{"nbformat":4,"nbformat_minor":2,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"06_Bayes_spam.ipynb","provenance":[{"file_id":"1BY9TSukNLV3VgtNdHpcgWofeAtVF4yku","timestamp":1573037493591}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","source":["# **SPAM vs. naiwny klasyfikator Bayesa**"],"metadata":{"id":"PNDQCDSFVdQ4"}},{"cell_type":"markdown","source":["## Wprowadzenie\n","Nigeryjski książę wciąż zarabia na użytkownikach elektronicznych skrzynek pocztowych ponad 700 tys. dolarów rocznie ([źródło](https://www.cnbc.com/2019/04/18/nigerian-prince-scams-still-rake-in-over-700000-dollars-a-year.html))! Jak to możliwe?\n","\n","Pierwsza przyczyna jest natury psychologicznej. Ofiary są poddawane \"perfekcyjnej burzy pokuszeń\", jak ujął to psycholog w wywiadzie, do którego linka dałam Wam powyżej. Spammerzy łączą granie na ludzkiej chciwości, ale także na pragnieniu bycia bohaterem. W końcu kto nie chciałby zarobić na byciu wspaniałomyślnym i szczodrym? W tej kwestii możemy pracować wyłącznie nad sobą.\n","\n","Możemy za to pracować nad filtrami antyspamowymi. Użyjemy techniki, która nazywa się \"worek ze słowami\" (bag of words) w połączeniu z naiwnym klasyfikatorem Bayesa. Choć to prosty klasyfikator, z powodzeniem jest używany współcześnie (np. [SpamAssassin](https://cwiki.apache.org/confluence/display/spamassassin/BayesInSpamAssassin)).\n","\n","Notebook oparty na tutorialach:\n","*   https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73\n","*   https://towardsdatascience.com/spam-filtering-using-naive-bayes-98a341224038\n"],"metadata":{"id":"seqEdVR1VdQ7"}},{"cell_type":"markdown","source":["## Import danych treningowych\n","https://www.kaggle.com/uciml/sms-spam-collection-dataset\n","\n","To dane przygotowane przez Almeida et al. na podstawie forum brytyjskiego, gdzie użytkownicy skarżą się na spamowe SMSy. Każdy wiersz składa się z kolumny opisującej czy wiadomość jest spamem, czy nie ('spam' czy 'ham'), a druga zawiera treść wiadomości."],"metadata":{"id":"_ZJI7KHjVdQ7"}},{"cell_type":"markdown","source":["Jak na ćwiczeniach o regresji logistycznej, możemy pobrać zestaw danych z GitHuba:"],"metadata":{"id":"x110k8pa-KD8"}},{"cell_type":"code","execution_count":null,"source":["!git clone https://github.com/Shmoo137/uczenie-maszynowe-2021-22"],"outputs":[],"metadata":{"id":"juQhPAwu-j6j"}},{"cell_type":"code","execution_count":null,"source":["folder = '/content/uczenie-maszynowe-2021-22/dane/' # tu się domyślnie zapisuje pobrane repo z GitHuba, a dane są w folderze \"dane\""],"outputs":[],"metadata":{"id":"FLHnLiSv-s6v"}},{"cell_type":"markdown","source":["Do pracy z danymi tekstowymi bardzo przydatna jest biblioteka [pandas](https://www.shanelynn.ie/using-pandas-dataframe-creating-editing-viewing-data-in-python/)."],"metadata":{"id":"qDclCxP2hhoJ"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\r\n","import pandas as pd"],"outputs":[],"metadata":{"id":"cWBDlNPHVdQ9"}},{"cell_type":"code","execution_count":null,"source":["mails = pd.read_csv(folder + 'spam_dataset.csv', encoding='latin-1')\r\n","mails.head()"],"outputs":[],"metadata":{"id":"JHEGrXdx97uU"}},{"cell_type":"markdown","source":["Wyczyśćmy ten zbiór danych. Usuńmy niepotrzebne kolumny i zastąpmy nazwy 'v1' i 'v2' czymś bardziej przyjaznym."],"metadata":{"id":"054a8tEtDWw2"}},{"cell_type":"code","execution_count":null,"source":["mails = mails.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\r\n","mails.head()"],"outputs":[],"metadata":{"id":"_e503qPbB-xa"}},{"cell_type":"code","execution_count":null,"source":["mails = mails.rename(columns={\"v1\": \"klasa\", \"v2\": \"tekst\"})\r\n","mails.head()"],"outputs":[],"metadata":{"id":"46VG63JADgYM"}},{"cell_type":"markdown","source":["Zobaczmy jak wyglądają przykładowe dane o numerze jakimkolwiek."],"metadata":{"id":"Xr86NzYAVdRF"}},{"cell_type":"code","execution_count":null,"source":["id = 57"],"outputs":[],"metadata":{"id":"kBsb284aVdRG"}},{"cell_type":"markdown","source":["Treść wiadomości:"],"metadata":{"id":"gdn7hSzUVdRJ"}},{"cell_type":"code","execution_count":null,"source":["mails['tekst'][id]"],"outputs":[],"metadata":{"id":"RONF-O6yVdRJ"}},{"cell_type":"markdown","source":["Kategoria:"],"metadata":{"id":"JOUTxbowVdRM"}},{"cell_type":"code","execution_count":null,"source":["mails['klasa'][id]"],"outputs":[],"metadata":{"id":"sIkLqoHBVdRN"}},{"cell_type":"markdown","source":["Ile mamy tych maili?"],"metadata":{"id":"7wLflQN1VdRP"}},{"cell_type":"code","execution_count":null,"source":["mails.shape"],"outputs":[],"metadata":{"id":"575SnOW9VdRP"}},{"cell_type":"markdown","source":["## Analiza częstości występowania słów w obu klasach za pomocą biblioteki WordCloud\n","\n","To biblioteka pozwalająca generować śliczne obrazki, na których wielkość słów odpowiada częstości jego występowania w danym zbiorze."],"metadata":{"id":"tFpUrBiRgFiV"}},{"cell_type":"code","execution_count":null,"source":["!pip install wordcloud\r\n","import wordcloud"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.17.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n"]}],"metadata":{"id":"lpfU-WXKg5CY","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1573802952633,"user_tz":-60,"elapsed":3633,"user":{"displayName":"Anna Dawid","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBMAlqIzrWbyBbGSDvCFuCvvSN7Xx3h3HRKaToc0r4=s64","userId":"02862484648310443813"}},"outputId":"80bda897-0e28-41b9-e7bf-3859858a333d"}},{"cell_type":"code","execution_count":null,"source":["from wordcloud import WordCloud\r\n","import matplotlib.pyplot as plt\r\n","\r\n","spam_words = \" \".join(list(mails [mails['klasa']=='spam']['tekst'] ))\r\n","spam_plot = WordCloud(width = 512, height = 512).generate(spam_words)\r\n","\r\n","plt.figure(figsize=(10,8))\r\n","plt.imshow(spam_plot)"],"outputs":[],"metadata":{"id":"L28LyPkEivX2"}},{"cell_type":"markdown","source":["Zrób to samo dla smsów nie będących spamem:"],"metadata":{"id":"Hctqwpr1B5Q_"}},{"cell_type":"code","execution_count":null,"source":["ham_words = ..."],"outputs":[],"metadata":{"id":"1SEOtnR0B5rA"}},{"cell_type":"markdown","source":["Przygotujmy dane do treningu i testu klasyfikatora:"],"metadata":{"id":"GxelOYTFVdRR"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.model_selection import train_test_split\r\n","\r\n","X = mails.tekst\r\n","y = mails.klasa\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"],"outputs":[],"metadata":{"id":"61E4BL3uVdRS"}},{"cell_type":"markdown","source":["Przekodowujemy wiadomości na wektory cech.  Korzystamy z funkcji: [sklearn.feature_extraction.text.CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"],"metadata":{"id":"gsnhFFc9VdRU"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.feature_extraction.text import CountVectorizer\r\n","\r\n","vectorizer = ... # stwórz instancje obiektu CountVectorizer\r\n","X_train = ... # naucz vectorizer słownika i przetransformuj dane uczące"],"outputs":[],"metadata":{"id":"WvM-XCWXVdRV"}},{"cell_type":"markdown","source":["Wypisz rozmiary danych treningowych:"],"metadata":{"id":"NMnNeNTdVdRX"}},{"cell_type":"code","execution_count":null,"source":["print(\"Dane treningowe: n_samples: %d, n_features: %d\" % X_train.shape)"],"outputs":[],"metadata":{"id":"Nky-W5gwVdRX"}},{"cell_type":"markdown","source":["Dane uczące są przechowywane w macierzy rzadkiej (sparse matrix). Proszę podejrzeć jak wyglądają tak przekodowane dane:"],"metadata":{"id":"hTx3RGrsVdRZ"}},{"cell_type":"code","execution_count":null,"source":["print(X_train[57])"],"outputs":[],"metadata":{"id":"__sbSUXJVdRb"}},{"cell_type":"markdown","source":[" Wektoryzujemy też dane testowe, wykorzystując już stworzony na podstawie danych treningowych wektor słów:"],"metadata":{"id":"MCxWJnnSVdRd"}},{"cell_type":"code","execution_count":null,"source":["X_test = ... # nie twórz nowego vectorizera, użyj gotowego, inaczej maszyna nie będzie potrafiła analizować danych testowych\r\n","print(\"Dane testowe: n_samples: %d, n_features: %d\" % X_test.shape)"],"outputs":[],"metadata":{"id":"T6GwugsoVdRe"}},{"cell_type":"markdown","source":["Odwrotne mapowanie z cech na słowa:"],"metadata":{"id":"zHsTCZS6VdRg"}},{"cell_type":"code","execution_count":null,"source":["feature_names = vectorizer.get_feature_names()\r\n","feature_names = np.asarray(feature_names)"],"outputs":[],"metadata":{"id":"ka3nqKbhVdRh"}},{"cell_type":"markdown","source":["Tworzymy instancję i uczymy klasyfikator MultinomialNB"],"metadata":{"id":"YmoXumisVdRj"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.naive_bayes import MultinomialNB\r\n","\r\n","clf = ...\r\n","clf.fit..."],"outputs":[],"metadata":{"id":"FyJmhv-VVdRk"}},{"cell_type":"markdown","source":["## Ocena jakości: jak zwykle będziemy korzystać z funkcji zaimplementowanych w [sci-kit](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"],"metadata":{"id":"0kWchjUPVdRn"}},{"cell_type":"code","execution_count":null,"source":["y_pred = ... # obliczamy predykcję dla tekstów ze zbioru testowego"],"outputs":[],"metadata":{"id":"U6DNyk0qVdRo"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","accur = ... # dokładność\n","print(\"Dokładność: %0.3f\" % accur)\n","print(\"Classification report:\") # wypisz raport klasyfikacji \n","...\n","\n","print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n","..."],"outputs":[],"metadata":{"id":"ktsCYepybxqu"}},{"cell_type":"markdown","source":["Sprawdźmy, czego właściwie maszyna się nauczyła:"],"metadata":{"id":"JXqzqM0cVdRs"}},{"cell_type":"code","execution_count":null,"source":["print(\"Słowa, które z największą pewnością wskazują maszynie, że wiadomość to spam:\")\n","top10 = np.argsort(clf.coef_[0])[-10:]\n","bottom10 = np.argsort(clf.coef_[0])[:10]\n","print(feature_names[top10])\n","\n","print(\"Słowa najmniej istotne przy klasyfikacji:\")\n","print(feature_names[bottom10])"],"outputs":[],"metadata":{"id":"Br2t5MLZVdRt"}},{"cell_type":"markdown","source":["## Zastanówmy się, czy możemy jakoś ułatwić zadanie maszynie, wykorzystując naszą znajomość języka"],"metadata":{"id":"mJv9ICOnkEqB"}},{"cell_type":"markdown","source":["### Wygładzanie Laplace'a\n","\n","Poszukajcie słowa, które nie występuje w zbiorze treningowym."],"metadata":{"id":"LE93eYVjs2EY"}},{"cell_type":"code","execution_count":null,"source":["id = np.where(feature_names == ...)\n","print(id)\n","\n","our_message = ...\n","vectorized_message = vectorizer.transform([our_message])\n","clf.predict(vectorized_message)"],"outputs":[],"metadata":{"id":"4G9PKlmFrCXP"}},{"cell_type":"markdown","source":["### Stemming (nawet nie będę próbować tego tłumaczyć na polski, to [bogate](https://pl.bab.la/slownik/angielski-polski/stemming) znaczeniowo słowo)\n","\n","Polega na ujednoliceniu słów o tym samym rdzeniu znaczeniowym (o czym maszyna, oczywiście, nie ma szans wiedzieć). Np. dzięki stemmingowi słowa \"go\", \"going\" i \"goes\" są przyporządkowane tylko jednemu słowu \"go\". Można np. użyć gotowego algorytmu stemmingowego o nazwie [Porter Stemmer](https://tartarus.org/martin/PorterStemmer/)."],"metadata":{"id":"pCgizjFcmQOr"}},{"cell_type":"code","execution_count":null,"source":["id1 = np.where(feature_names == 'going')\n","id2 = np.where(feature_names == 'go')\n","print(id1, id2)"],"outputs":[],"metadata":{"id":"oScLywVekLm4"}},{"cell_type":"code","execution_count":null,"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","\n","message = 'Applying classical methods of machine learning to the study of quantum systems (sometimes called quantum machine learning) is the focus of an emergent area of physics research'\n","words = word_tokenize(message)\n","\n","stemmer = PorterStemmer()\n","words = [stemmer.stem(word) for word in words]\n","\n","print(words)"],"outputs":[],"metadata":{"id":"Y3tQCtFu8JEU"}},{"cell_type":"markdown","source":["Powtórzmy trening i testowanie naszego klasyfikatora na danych poddanych stemmingowi:"],"metadata":{"id":"TRkUybiA9oit"}},{"cell_type":"code","execution_count":null,"source":["stemmer = PorterStemmer()\n","analyzer = CountVectorizer().build_analyzer()\n","\n","def stemmed_words(doc):\n","    return (stemmer.stem(w) for w in analyzer(doc))\n","\n","vectorizer = CountVectorizer(analyzer=stemmed_words)"],"outputs":[],"metadata":{"id":"G5AS9K7j8kpu"}},{"cell_type":"code","execution_count":null,"source":["X = ...\n","y = ...\n","X_train, X_test, y_train, y_test = ...\n","# vectorizer z PorterStemmerem został już stworzony w okienku wyżej\n","X_train = vectorizer.fit_transform(...) # naucz vectorizer słownika i przetransformuj dane uczące\n","X_test = ... # przetransformuj dane uczące korzystając z tego samego słownika\n","clf = ...\n","clf.fit...\n","\n","y_pred = ...\n","accur = ... # dokładność\n","print(\"Dokładność: %0.3f\" % accur)\n","print(\"Classification report:\") # wypisz raport klasyfikacji \n","...\n","\n","print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n","...\n","\n","feature_names = vectorizer.get_feature_names()\n","feature_names = np.asarray(feature_names)\n","\n","print(\"Słowa, które z największą pewnością wskazują maszynie, że wiadomość to spam:\")\n","top10 = np.argsort(clf.coef_[0])[-10:]\n","bottom10 = np.argsort(clf.coef_[0])[:10]\n","print(feature_names[top10])\n","\n","print(\"Słowa najmniej istotne przy klasyfikacji:\")\n","print(feature_names[bottom10])"],"outputs":[],"metadata":{"id":"asGIjB4J-Jrq"}},{"cell_type":"markdown","source":["## Gdybyście byli spammerami... Co moglibyście zrobić, znając tę technikę antyspamową?"],"metadata":{"id":"_WxLEc7CASHi"}},{"cell_type":"markdown","source":["### Stosowanie znaków specjalnych zamiast liter"],"metadata":{"id":"hOLZbs_5AY7Z"}},{"cell_type":"code","execution_count":null,"source":["our_message = vectorizer.transform(['call for free'])\n","print(clf.predict(our_message))\n","\n","our_tricky_message = vectorizer.transform(['c@ll for free'])\n","print(clf.predict(our_tricky_message))"],"outputs":[],"metadata":{"id":"qccAaFGY_C8Y"}},{"cell_type":"markdown","source":["### Wysyłanie obrazków z tekstem!\n","-> nakładki OCR (ang. optical character recognition)"],"metadata":{"id":"JCAXu4P9AzfJ"}},{"cell_type":"markdown","source":["Jakieś inne pomysły? :)"],"metadata":{"id":"CbYzjoYFBDs-"}}]}