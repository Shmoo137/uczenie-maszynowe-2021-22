{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_Miary_jakości.ipynb","provenance":[{"file_id":"16srziWO2XRWYY8AVY9Px_05RQQdYY5jA","timestamp":1571847683761}],"collapsed_sections":[]},"kernelspec":{"display_name":"ENV","language":"python","name":"env"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZLsPh6QLqvsd","colab_type":"text"},"source":["# Zanim przystąpimy do ćwiczenia\n","W tym ćwiczeniu skorzystamy z modułu sklearn (scikit-learn) przeznaczonego do uczenia maszynowego. Zawiera wiele zoptymalizowanych i przydatnych funkcji i algorytmów. Alternatywnymi frameworkami są np. PyTorch, Tensorflow, Keras, Caffe2, chociaż z obserwacji środowiska wynika, że dominują raczej PyTorch i Tensorflow.\n"]},{"cell_type":"code","metadata":{"id":"ZEDtJYrxqvsg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1571933160324,"user_tz":-120,"elapsed":802,"user":{"displayName":"Anna Dawid","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBMAlqIzrWbyBbGSDvCFuCvvSN7Xx3h3HRKaToc0r4=s64","userId":"02862484648310443813"}},"outputId":"7307205d-0342-4fbe-85a0-533bcc1e8301"},"source":["import sklearn\n","print('Zainstalowana wersja scikit-learn: {}.'.format(sklearn.__version__))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Zainstalowana wersja scikit-learn: 0.21.3.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7wFBQnvOqvsr","colab_type":"text"},"source":["Na stronie przedmiotu znajduje się instrukcja konfiguracji środowiska w przypadku pracy lokalnej, a nie w colabie. Może (nie musi) być przydatna dla osób pracujących na własnych laptopach:\n","\n","https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/konfiguracja"]},{"cell_type":"code","metadata":{"id":"mmIFNq4Bqvst","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (20,10) # aby wykresy w Colabie były większe\n","\n","import numpy as np\n","from scipy import diag, interp\n","from itertools import cycle\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn import metrics\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YibBq2d4qvs0","colab_type":"text"},"source":["# Ćwiczenie: Walidacja krzyżowa\n","Już na ostatnich ćwiczeniach przerobiliśmy walidację krzyżową. Teraz przyjrzymy się jej bliżej i sprawdźmy efekt wspomniany na wykładzie, czyli efekt częstości występowania.\n","\n","* W tym ćwiczeniu przyjrzymy się jak miary jakości klasyfikatora zależą od proporcji klas w zbiorze uczącym i od rozmiaru zbioru uczącego\n","* Klasyfikatorem będzie nadal regresja logistyczna, ale tym razem zamiast korzystać z własnej implementacji, skorzystamy z gotowej wersji bibliotecznej z modułu [scikit-learn] (http://scikit-learn.org/stable/index.html)\n"]},{"cell_type":"markdown","metadata":{"id":"7GiQUZ_Cqvs1","colab_type":"text"},"source":["Dzisiaj znowu wygenerujemy sztucznie dane, które później będziemy klasyfikować, a to po to, aby mieć pełną kontrolę nad częstością występowania klas.\n","\n","Poniższa funkcja przyjmuje za argument liczbę przykładów, którą ma wygenerować.\n","Wygenerowane przykłady będą pochodziły z dwóch dwuwymiarowych rozkładów normalnych = klas określonych przez średnią mu[klasa] i macierz kowariancji cov[klasa]. Możemy te cechy dowolnie zmieniać."]},{"cell_type":"code","metadata":{"id":"WFTUaX6wqvs3","colab_type":"code","colab":{}},"source":["def gen(ile):\n","    mu = [(-1,0.5),(1.2,4)] #średnie klas\n","    cov = [diag([3,3]), diag([4,1.7])] #macierze kowariancji dla klas\n","    \n","    X = np.zeros((ile*len(mu), 2)) # miejsce na dane wejściowe\n","    Y = np.zeros((ile*len(mu), 1),dtype = int) # miejsce na dane wyjściowe\n","    for klasa in range(len(mu)):\n","        X[klasa*ile:(klasa+1)*ile] = np.random.multivariate_normal(mu[klasa],cov[klasa],ile)\n","        Y[klasa*ile:(klasa+1)*ile] = klasa\n","    Y = Y.ravel()\n","    return (X,Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYxjhhHsqvs9","colab_type":"text"},"source":["Testujemy tę funkcję, generujemy 50 przykładów, pierwszych 5 wypisujemy, wszystkie rysujemy za pomocą funkcji `scatter`. Pamiętajmy, że za każdym wywołaniem funkcji będziemy dostawać różne dane (jako że są one generowane przez np.random)."]},{"cell_type":"code","metadata":{"id":"8Df_pwsnqvs-","colab_type":"code","colab":{}},"source":["X,Y = gen(50)\n","print('X: ', X[0:5,:])\n","print('Y: ', Y[0:5])\n","plt.scatter(X[:,0], X[:,1], c = Y, cmap=plt.cm.Set1, alpha = 0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JWmqK-c4qvtB","colab_type":"text"},"source":["# Klasy równoliczne"]},{"cell_type":"markdown","metadata":{"id":"gmeJZgcxqvtC","colab_type":"text"},"source":["## Zaobserwujmy zmienność miar jakości klasyfikatora przy wybieraniu podzbiorów do uczenia i testowania ze zbioru uczącego.\n","* do podziałów zbioru zastosujemy funkcję [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n","* do obliczania miar jakości zastosujemy funkcje z modułu [sklearn.metrics](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)"]},{"cell_type":"markdown","metadata":{"id":"ieaSg8JlqvtD","colab_type":"text"},"source":["Wykonaj podział zbioru uczącego tak, aby zestaw testowy stanowił 20% całego zbioru uczącego. Zilustruj za pomocą `scatter` punkty należące do części uczącej i do części testowej.\n","\n","W razie wątpliwości, sprawdź funkcję w dokumentacji. Warto to robić dla wszelkich problemów, funkcje i metody z bibliotek ML są zazwyczaj dobrze opisane.\n","\n","* Podział:"]},{"cell_type":"code","metadata":{"id":"EHbXlRRlqvtE","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = ?)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sqsemxJQqvtG","colab_type":"text"},"source":["* Ilustracja:"]},{"cell_type":"code","metadata":{"id":"3drSx4ScqvtH","colab_type":"code","colab":{}},"source":["plt.scatter(X_train[:,0], X_train[:,1], c = y_train, cmap=plt.cm.Set1, alpha = 0.5)\n","plt.scatter(X_test[:,0], X_test[:,1], c = y_test, cmap=plt.cm.Set1, alpha = 0.5, marker = '*' )\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sTMtVm5-qvtK","colab_type":"text"},"source":["Regresja logistyczna zaimplementowana jest w klasie [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Tworzymy instancję obiektu tej klasy. Jeśli nie ustawimy żadnego algorytmu optymalizacji, to domyślnie zostanie ustawiony solver 'lbfgs', ale jednocześnie generuje to irytujący warning, więc lepiej zadeklarować go z góry."]},{"cell_type":"code","metadata":{"id":"rTYUHUEKqvtL","colab_type":"code","colab":{}},"source":["model = LogisticRegression(solver = 'lbfgs')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nzoph_sVqvtO","colab_type":"text"},"source":["Uczymy go  na zbiorze uczącym:"]},{"cell_type":"code","metadata":{"id":"v4kNQhQ1qvtP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1571934160168,"user_tz":-120,"elapsed":696,"user":{"displayName":"Anna Dawid","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBMAlqIzrWbyBbGSDvCFuCvvSN7Xx3h3HRKaToc0r4=s64","userId":"02862484648310443813"}},"outputId":"094ec1f4-817e-4c1d-ebd1-9719344a5534"},"source":["model.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='warn', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"9VV0FB_gqvtR","colab_type":"text"},"source":["Wykonujemy predykcje dla zbioru testowego:"]},{"cell_type":"code","metadata":{"id":"AwAdNSmXqvtS","colab_type":"code","colab":{}},"source":["y_pred = model.predict(X_test)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKSvOoqXqvtU","colab_type":"text"},"source":["Efekty można obejrzeć za pomocą macierzy pomyłek: "]},{"cell_type":"code","metadata":{"id":"cFK3Iy5HqvtV","colab_type":"code","colab":{}},"source":["print(metrics.confusion_matrix(y_test, y_pred))\n","tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n","print('TN: ',tn,'FP: ', fp, 'FN: ', fn, 'TP: ', tp )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-PATG0geqvtX","colab_type":"text"},"source":["W pętli powtórzymy proces podziału zbioru uczącego i dla każdego podziału obliczmy miary jakości:\n","* precyzja pozytywna: (positive predictive value (PPV), precision). Odpowiada na pytanie: \"Jeśli wynik testu jest pozytywny, jakie jest prawdopodobieństwo, że osoba badana jest chora?\"\n","\n","$\\qquad$ $PPV = \\frac{TP}{P'}=\\frac{TP}{ TP + FP}$\n","\n","* czułość: Prawdopodobieństwo, że klasyfikacja będzie poprawna pod warunkiem, że przypadek jest pozytywny (ang. True Positive Rate, Recall). Jest to np. prawdopodobieństwo, że test wykonany dla osoby chorej wykaże, że jest ona chora.\n","\n","$\\qquad$ $TPR = \\frac{TP}{ P} = \\frac{TP} { TP+FN}$\n","\n","\n","* dokładność (accuracy (ACC)): Prawdopodobieństwo prawidłowej klasyfikacji.\n","\n","$\\qquad$ $ACC = \\frac{TP + TN}{P + N}$\n","\n","* F1-score: średnia harmoniczna z precyzji i czułości:\n","\n","$\\qquad$ $F_1= 2 \\frac{PPV  \\cdot TPR}{PPV+TPR}= \\frac{2TP}{ 2TP+FP+FN}$\n","Miara ta daje ocenę balansu między czułością a precyzją. Miara ta nie uwzględnia wyników prawdziwie negatywnych.\n","\n","* współczynnik korelacji Matthews ( Matthews correlation coefficient):\n","\n","$\\qquad$ $\n","\\text{MCC} = \\frac{ TP \\cdot TN - FP \\cdot FN } {\\sqrt{ (TP + FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }\n","$\n","\n","  * Ten współczynnik uwzględnia wyniki zarówno prawdziwie jaki i fałszywie pozytywne i negatywne i jest na ogół uważany jako zrównoważona miara, która może być stosowana nawet wtedy, gdy klasy są bardzo różnej liczebności. \n","  * MCC jest w istocie współczynnikiem korelacji pomiędzy obserwowanymi i przewidywanymi klasyfikacjami binarnymi; zwraca wartość od -1 do +1. \n","    * Współczynnik +1 odpowiada idealnej klasyfikacji, \n","    * 0 nie lepiej niż losowe przypisanie wyniku i \n","    * -1 oznacza całkowitą niezgodę między klasyfikacją  i stanem faktycznym."]},{"cell_type":"code","metadata":{"id":"T_DmAtvsqvtY","colab_type":"code","colab":{}},"source":["model = ? # stwórz instancję klasyfikatora\n","for i in range(10):\n","    X_train, X_test, y_train, y_test = ? # podziel zbiór z 20% do testowania\n","\n","\n","    ? # naucz klasyfikator\n","    y_pred = ? # wykonaj predykcję dla zbioru testowego\n","  \n","    \n","    PPV = metrics.precision_score(y_test, y_pred)\n","    REC = metrics.recall_score(y_test, y_pred)\n","    ACC = metrics.accuracy_score(y_test, y_pred)\n","    F1 = metrics.f1_score(y_test, y_pred)\n","    MCC = metrics.matthews_corrcoef(y_test, y_pred)\n","    \n","    print('PPV = {p:.3f} REC = {r:.3f} ACC = {a:.3f} F1 = {f:.3f} MCC =  {m:.3f}  '.format(a=ACC,f=F1,m=MCC,p=PPV,r=REC))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gorayUYfqvtc","colab_type":"text"},"source":["Widzimy, że miary zmieniają się przy każdym losowaniu.\n","\n","Najczęściej stosuje się nie takie losowe podziały, ale systematyczny podział `k`-krotny (k-fold cross-validation). Procedura wygląda wówczas następująco:\n","* Dzielimy zbiór uczący (X i y) na `k` równych części\n","* Odkładamy 1-szą część jako dane testowe, \n","* Na pozostałych `k-1` częściach uczymy klasyfikator\n","* Obliczamy miary jakości na tej odłożonej części\n","* Wybieramy 2-gą część jako dane testowe\n","* Na pozostałych `k-1` częściach uczymy klasyfikator\n","* Obliczamy miary jakości na tej odłożonej części\n","* $\\vdots$\n","\n","W bibliotece `sklearn` mamy do tego wygodną funkcję `cross_val_score`:"]},{"cell_type":"code","metadata":{"id":"Om4ZI2NCqvtd","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import cross_val_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b3RLAd8aqvtf","colab_type":"text"},"source":["Zobaczmy jak działa:"]},{"cell_type":"code","metadata":{"id":"8xn_Q1HEqvtg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1571934289525,"user_tz":-120,"elapsed":708,"user":{"displayName":"Anna Dawid","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBMAlqIzrWbyBbGSDvCFuCvvSN7Xx3h3HRKaToc0r4=s64","userId":"02862484648310443813"}},"outputId":"b2daa0aa-4528-4c86-b16c-f7c8f7e99bee"},"source":["ppv = cross_val_score(model, X, Y, cv=10, scoring='precision')\n","print('PPV = {0:.2f} +/- {1:.2f}'.format(ppv.mean(),ppv.std()))\n","rec = cross_val_score(model, X, Y, cv=10, scoring='recall')\n","print('REC = {0:.2f} +/- {1:.2f}'.format(rec.mean(),rec.std()))\n","acc = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\n","print('ACC = {0:.2f} +/- {1:.2f}'.format(acc.mean(),acc.std()))\n","f1 = cross_val_score(model, X, Y, cv=10, scoring='f1')\n","print('F1 = {0:.2f} +/- {1:.2f}'.format(f1.mean(),f1.std()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PPV = 0.88 +/- 0.10\n","REC = 0.90 +/- 0.13\n","ACC = 0.88 +/- 0.09\n","F1 = 0.88 +/- 0.09\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9OAmVCSKqvti","colab_type":"text"},"source":["Dla kompletu zbadajmy jeszcze krzywą ROC. Tym razem też posłużymy się funkcjami bibliotecznymi."]},{"cell_type":"code","metadata":{"id":"g99d62Wvqvtj","colab_type":"code","colab":{}},"source":["skf  = StratifiedKFold(n_splits=6)\n","model = ?\n","tprs = []\n","aucs = []\n","mean_fpr = np.linspace(0, 1, 100)\n","\n","\n","i = 0\n","for train, test in skf.split(X, Y):\n","    model.fit(X[train], Y[train]) # fitujemy regresję\n","    probas_ = model.predict_proba(X[test])  # obliczamy prawdopodobieństwa przynależności przykładów testowych \n","                                            # do klas wg. wyuczonego klasyfikatora \n","                                            # (zwraca on w danym wierszu prawdopodobieństaw dla każdej z możliwych klas)\n","   \n","    # Obliczamy punkty krzywej ROC \n","    fpr, tpr, thresholds = metrics.roc_curve(Y[test], probas_[:, 1]) # względem prawdopodobieństwa klasy 1 \n","    tprs.append(interp(mean_fpr, fpr, tpr))\n","    tprs[-1][0] = 0.0\n","    # i powierzchnię pod krzywą\n","    roc_auc = metrics.auc(fpr, tpr)\n","    aucs.append(roc_auc)\n","    # rysujemy krzywą \n","    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n","             label='ROC dla podziału %d (AUC = %0.2f)' % (i, roc_auc))\n","    i += 1\n","    \n","    \n","plt.plot([0, 1], [0, 1], linestyle='--', lw = 2, color='r',\n","         label = 'Losowa klasa', alpha = 0.8)\n","      \n","\n","# poniżej podsumowanie: oliczanie średnich i standardowych odchyleń, cieniowanie przedziału ufności \n","mean_tpr = np.mean(tprs, axis=0)\n","mean_tpr[-1] = 1.0\n","mean_auc = metrics.auc(mean_fpr, mean_tpr)\n","std_auc = np.std(aucs)\n","plt.plot(mean_fpr, mean_tpr, color='b',\n","         label=r'Średni ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n","         lw=2, alpha=.8)\n","\n","std_tpr = np.std(tprs, axis=0)\n","tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n","tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n","plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n","                 label=r'$\\pm$ 1 std. dev.')\n","\n","plt.xlim([-0.05, 1.05])\n","plt.ylim([-0.05, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oJ-Nox9uqvtl","colab_type":"text"},"source":["Sprawdźmy jak miary jakości zależą od rozmiaru zbioru uczącego:"]},{"cell_type":"code","metadata":{"id":"_T0JqaIIqvtn","colab_type":"code","colab":{}},"source":["N = 10\n","PPV_mean = np.zeros((N,1))\n","PPV_std = np.zeros((N,1))\n","REC_mean = np.zeros((N,1))\n","REC_std = np.zeros((N,1))\n","ACC_mean = np.zeros((N,1))\n","ACC_std = np.zeros((N,1))\n","F1_mean = np.zeros((N,1))\n","F1_std = np.zeros((N,1))\n","\n","n = 30 + np.floor(np.logspace(1,4,N)).astype(int)\n","\n","for i in range(N):\n","    X,Y = gen(int(n[i]))\n","    model = ?\n","    ppv = ?\n","    PPV_mean[i] = ppv.mean()\n","    PPV_std[i]  = ppv.std()\n","    rec = ?\n","    REC_mean[i]  = rec.mean()\n","    REC_std[i]  = rec.std()\n","    acc = ?\n","    ACC_mean[i]  = acc.mean()\n","    ACC_std[i]  = acc.std()\n","    f1 = ?\n","    F1_mean[i]  = f1.mean()\n","    F1_std[i]  = f1.std()\n","\n","ax = plt.subplot(1,1,1)\n","plt.errorbar(n, PPV_mean, yerr = PPV_std.ravel())\n","plt.errorbar(n+2, REC_mean, yerr = REC_std.ravel())\n","plt.errorbar(n+4, ACC_mean, yerr = ACC_std.ravel())\n","plt.errorbar(n+6, F1_mean, yerr = F1_std.ravel())\n","plt.legend(('PPV','REC','ACC','F1'))\n","ax.set_xscale(\"log\", nonposx='clip')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ffs87mqHqvtr","colab_type":"text"},"source":["# Klasy niezrównoważone"]},{"cell_type":"markdown","metadata":{"id":"ml0Tk0ngqvts","colab_type":"text"},"source":["Wytwórzymy teraz dane, w których jedna z klas jest M-krotnie liczniejsza. "]},{"cell_type":"code","metadata":{"id":"PrYWH1_pqvtt","colab_type":"code","colab":{}},"source":["def gen_rozne(ile, M):\n","    mu = [(-1,0.5),(1,4)]\n","    #mu = [(-1,0.5),(-1,0.5)]\n","    cov = [diag([1.7,1.8]), diag([1.5,0.7])]\n","    X = np.zeros(((M+1)*ile, 2)) # miejsce na dane wejściowe\n","    Y = np.zeros(((M+1)*ile, 1),dtype = int) # miejsce na dane wyjściowe\n","    print(Y.shape)\n","    klasa = 0\n","    X[0:ile] = np.random.multivariate_normal(mu[klasa],cov[klasa],ile)\n","    Y[0:ile] = klasa\n","    klasa =1 \n","    X[ile:ile+ile*M] = np.random.multivariate_normal(mu[klasa],cov[klasa],ile*M)\n","    Y[ile:ile+ile*M] = klasa\n","    Y = Y.ravel()\n","    print(np.sum(Y==0), np.sum(Y==1) )\n","    return (X,Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"simmwRmjqvtw","colab_type":"text"},"source":["Oglądamy dane:"]},{"cell_type":"code","metadata":{"id":"2DUzukmBqvtx","colab_type":"code","colab":{}},"source":["X,Y = gen_rozne(30, 100)\n","plt.scatter(X[:,0], X[:,1] ,c = Y, cmap=plt.cm.Set1, alpha = 0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZL0aq9eBqvtz","colab_type":"text"},"source":["Obliczamy miary jakości dla danych niezrównoważonych przy podziale 10-krotnym. Zwróćmy uwagę na różnicę w wartościach 4 pierwszych miar i miary MCC:"]},{"cell_type":"code","metadata":{"id":"c5jm53Z3qvt0","colab_type":"code","colab":{}},"source":["ppv = ?\n","print('PPV = {0:.2f} +/- {1:.2f}'.format(ppv.mean(),ppv.std()))\n","rec = ?\n","print('REC = {0:.2f} +/- {1:.2f}'.format(rec.mean(),rec.std()))\n","acc = ?\n","print('ACC = {0:.2f} +/- {1:.2f}'.format(acc.mean(),acc.std()))\n","f1 = ?\n","print('F1 = {0:.2f} +/- {1:.2f}'.format(f1.mean(),f1.std()))\n","print('-----')\n","MCC=np.zeros((10,1))\n","for i in range(10):\n","    X_train, X_test, y_train, y_test = ? # test na 10% aby było podobnie jak dla podziału 10-krotnego\n","    ? # trenuj model\n","    y_pred = ? # predykcja dla zbioru testowego\n","    MCC[i] = metrics.matthews_corrcoef(y_test, y_pred)\n","print('MCC = {0:.2f} +/- {1:.2f}'.format(MCC.mean(),MCC.std()))  \n","   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NC-4END_qvt4","colab_type":"text"},"source":["Teraz spróbujemy zobaczyć czy da się to poprawić, jeśli w podziałach zadbać o zachowanie proporcji klas. Można to łatwo zrobić za pomocą funkcji `StratifiedKFold`, zwraca ona indeksy do zbioru treningowego i testowego:"]},{"cell_type":"code","metadata":{"id":"lRgNmNCdqvt6","colab_type":"code","colab":{}},"source":["skf = StratifiedKFold(n_splits = 4)\n","for train, test in skf.split(X, Y):  \n","    model.fit(X[train,:],Y[train])\n","    y_pred = model.predict(X[test,:]) \n","    y_test = Y[test]\n","    PPV = metrics.precision_score(y_test, y_pred)\n","    REC = metrics.recall_score(y_test, y_pred)\n","    ACC = metrics.accuracy_score(y_test, y_pred)\n","    F1 = metrics.f1_score(y_test, y_pred)\n","    MCC = metrics.matthews_corrcoef(y_test, y_pred)\n","    \n","    print('PPV = {p:.3f} REC = {r:.3f} ACC = {a:.3f} F1 = {f:.3f} MCC =  {m:.3f}  '.format(a=ACC,f=F1,m=MCC,p=PPV,r=REC))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uMyDC3Nqvt-","colab_type":"text"},"source":["Zbadajmy jeszcze krzywą ROC:"]},{"cell_type":"code","metadata":{"id":"27l3I5V9qvt_","colab_type":"code","colab":{}},"source":["skf  = StratifiedKFold(n_splits=6)\n","model = ?\n","tprs = []\n","aucs = []\n","mean_fpr = np.linspace(0, 1, 100)\n","\n","i = 0\n","for train, test in skf.split(X, Y):\n","    ? # fitujemy regresję\n","    probas_ = ?  # obliczamy prawdopodobieństwa przynależności przykładów testowych \n","                                            # do klas wg. wyuczonego klasyfikatora \n","                                            # (zwraca on w danym wierszu prawdopodobieństaw dla każdej z możliwych klas)\n","   \n","    # Obliczamy punkty krzywej ROC \n","    fpr, tpr, thresholds = metrics.roc_curve(Y[test], probas_[:, 1]) # względem prawdopodobieństwa klasy 1 \n","    tprs.append(interp(mean_fpr, fpr, tpr))\n","    tprs[-1][0] = 0.0\n","    # i powierzchnię pod krzywą\n","    roc_auc = metrics.auc(fpr, tpr)\n","    aucs.append(roc_auc)\n","    # rysujemy krzywą \n","    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n","             label='ROC dla podziału %d (AUC = %0.2f)' % (i, roc_auc))\n","    i += 1\n","    \n","    \n","plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n","         label='Losowa klasa', alpha=.8)\n","         \n","         \n","# poniżej podsumowanie: oliczanie średnich i standardowych odchyleń, cieniowanie przedziału ufności \n","mean_tpr = np.mean(tprs, axis=0)\n","mean_tpr[-1] = 1.0\n","mean_auc = metrics.auc(mean_fpr, mean_tpr)\n","std_auc = np.std(aucs)\n","plt.plot(mean_fpr, mean_tpr, color='b',\n","         label=r'Średni ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n","         lw=2, alpha=.8)\n","\n","std_tpr = np.std(tprs, axis=0)\n","tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n","tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n","plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n","                 label=r'$\\pm$ 1 std. dev.')\n","\n","plt.xlim([-0.05, 1.05])\n","plt.ylim([-0.05, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NOKh4VeeqvuD","colab_type":"text"},"source":["Powyższe obliczenia obliczenia proszę przeprowadzić dla klas, których rozkłady wyraźnie się różnią i dla takich które się pokrywają w znacznym stopniu. Trzeba podmienić średnie klas w funkcji generującej dane różnoliczne.\n","\n","# Jakie stąd płyną wnioski?\n"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"B-fCr9NPqvuE","colab_type":"text"},"source":["O czym chciałabym przeczytać w Waszych wnioskach:\n","\n","1) Jakie płyną konsekwencje z dużej różnicy częstości występowania dwóch klas?\n","\n","2) Które miary jakości są na ten efekt najmniej i najbardziej wrażliwe?\n","\n","3) Jak można przeciwdziałać efektowi częstości występowania?\n","\n","4) Jak miary jakości zależą od rozmiaru zbioru uczącego?\n","\n","5) Czy efekt częstości występowania ma taki sam czy różny wpływ na miary jakości w przypadku, gdy klasy pochodzą z rozkładów, które się znacząco pokrywają lub są mocno rozseparowane?"]}]}